{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "a=1\n",
    "b=2\n",
    "print(a+b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'Hello, TensorFlow!'\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "hello = tf.constant('Hello, TensorFlow!')\n",
    "sess = tf.Session()\n",
    "print(sess.run(hello))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Copyright 2016 The TensorFlow Authors. All Rights Reserved.\n",
    "#\n",
    "#  Licensed under the Apache License, Version 2.0 (the \"License\");\n",
    "#  you may not use this file except in compliance with the License.\n",
    "#  You may obtain a copy of the License at\n",
    "#\n",
    "#   http://www.apache.org/licenses/LICENSE-2.0\n",
    "#\n",
    "#  Unless required by applicable law or agreed to in writing, software\n",
    "#  distributed under the License is distributed on an \"AS IS\" BASIS,\n",
    "#  WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
    "#  See the License for the specific language governing permissions and\n",
    "#  limitations under the License.\n",
    "\"\"\"Convolutional Neural Network Estimator for MNIST, built with tf.layers.\"\"\"\n",
    "\n",
    "from __future__ import absolute_import\n",
    "from __future__ import division\n",
    "from __future__ import print_function\n",
    "\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "tf.logging.set_verbosity(tf.logging.INFO)\n",
    "\n",
    "\n",
    "def cnn_model_fn(features, labels, mode):\n",
    "  \"\"\"Model function for CNN.\"\"\"\n",
    "  # Input Layer\n",
    "  # Reshape X to 4-D tensor: [batch_size, width, height, channels]\n",
    "  #卷积神经网络会利用空间结构特征因此需要将一维向量转为二维图片结构即 1*784-->28*28 ，-1代表样本数量不固定  1表示color channel\n",
    "  # MNIST images are 28x28 pixels, and have one color channel\n",
    "  input_layer = tf.reshape(features[\"x\"], [-1, 28, 28, 1])\n",
    "\n",
    "  # Convolutional Layer #1\n",
    "  # Computes 32 features using a 5x5 filter with ReLU activation.\n",
    "  # Padding is added to preserve width and height.边界的加上pading使得卷积是输出与输入相同\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 1]\n",
    "  # Output Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  conv1 = tf.layers.conv2d(\n",
    "      inputs=input_layer,\n",
    "      filters=32,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "\n",
    "  # Pooling Layer #1\n",
    "  # First max pooling layer with a 2x2 filter and stride of 2 （缩小图片尺寸）\n",
    "  # Input Tensor Shape: [batch_size, 28, 28, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  pool1 = tf.layers.max_pooling2d(inputs=conv1, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Convolutional Layer #2\n",
    "  # Computes 64 features using a 5x5 filter.\n",
    "  # Padding is added to preserve width and height.\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 32]\n",
    "  # Output Tensor Shape: [batch_size, 14, 14, 64] 得到64个feature maps\n",
    "  conv2 = tf.layers.conv2d(\n",
    "      inputs=pool1,\n",
    "      filters=64,\n",
    "      kernel_size=[5, 5],\n",
    "      padding=\"same\",\n",
    "      activation=tf.nn.relu)\n",
    "#共14*14 *64\n",
    "  # Pooling Layer #2\n",
    "  # Second max pooling layer with a 2x2 filter and stride of 2\n",
    "  # Input Tensor Shape: [batch_size, 14, 14, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  pool2 = tf.layers.max_pooling2d(inputs=conv2, pool_size=[2, 2], strides=2)\n",
    "\n",
    "  # Flatten tensor into a batch of vectors\n",
    "  # Input Tensor Shape: [batch_size, 7, 7, 64]\n",
    "  # Output Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  pool2_flat = tf.reshape(pool2, [-1, 7 * 7 * 64])\n",
    "\n",
    "  # Dense Layer  全连接层\n",
    "  # Densely connected layer with 1024 neurons\n",
    "  # Input Tensor Shape: [batch_size, 7 * 7 * 64]\n",
    "  # Output Tensor Shape: [batch_size, 1024]\n",
    "  dense = tf.layers.dense(inputs=pool2_flat, units=1024, activation=tf.nn.relu)\n",
    "\n",
    "  # Add dropout operation; 0.6 probability that element will be kept  随机丢弃部分数据减轻过拟合\n",
    "  dropout = tf.layers.dropout(\n",
    "      inputs=dense, rate=0.4, training=mode == tf.estimator.ModeKeys.TRAIN)\n",
    "\n",
    "  # Logits layer\n",
    "  # Input Tensor Shape: [batch_size, 1024]\n",
    "  # Output Tensor Shape: [batch_size, 10]\n",
    "  logits = tf.layers.dense(inputs=dropout, units=10)\n",
    "\n",
    "  predictions = {\n",
    "      # Generate predictions (for PREDICT and EVAL mode)\n",
    "      \"classes\": tf.argmax(input=logits, axis=1),\n",
    "      # Add `softmax_tensor` to the graph. It is used for PREDICT and by the\n",
    "      # `logging_hook`.\n",
    "      \"probabilities\": tf.nn.softmax(logits, name=\"softmax_tensor\")\n",
    "  }\n",
    "  if mode == tf.estimator.ModeKeys.PREDICT:\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, predictions=predictions)\n",
    "\n",
    "  # Calculate Loss (for both TRAIN and EVAL modes)\n",
    "  loss = tf.losses.sparse_softmax_cross_entropy(labels=labels, logits=logits)\n",
    "\n",
    "  # Configure the Training Op (for TRAIN mode)\n",
    "  if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "    optimizer = tf.train.GradientDescentOptimizer(learning_rate=0.001)\n",
    "    train_op = optimizer.minimize(\n",
    "        loss=loss,\n",
    "        global_step=tf.train.get_global_step())\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, train_op=train_op)\n",
    "\n",
    "  # Add evaluation metrics (for EVAL mode)\n",
    "  eval_metric_ops = {\n",
    "      \"accuracy\": tf.metrics.accuracy(\n",
    "          labels=labels, predictions=predictions[\"classes\"])}\n",
    "  return tf.estimator.EstimatorSpec(\n",
    "      mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting MNIST-data/train-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/train-labels-idx1-ubyte.gz\n",
      "Extracting MNIST-data/t10k-images-idx3-ubyte.gz\n",
      "Extracting MNIST-data/t10k-labels-idx1-ubyte.gz\n",
      "INFO:tensorflow:Using default config.\n",
      "INFO:tensorflow:Using config: {'_save_checkpoints_secs': 600, '_num_worker_replicas': 1, '_num_ps_replicas': 0, '_tf_random_seed': None, '_save_summary_steps': 100, '_task_id': 0, '_master': '', '_session_config': None, '_is_chief': True, '_log_step_count_steps': 100, '_evaluation_master': '', '_save_checkpoints_steps': None, '_keep_checkpoint_max': 5, '_model_dir': '/tmp/mnist_convnet_model', '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f7abc8b2be0>, '_keep_checkpoint_every_n_hours': 10000, '_global_id_in_cluster': 0, '_task_type': 'worker', '_service': None}\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:probabilities = [[0.10561517 0.10468872 0.1067036  0.10686336 0.0985141  0.09689648\n",
      "  0.08010069 0.09202415 0.11219126 0.09640247]\n",
      " [0.10865244 0.09772936 0.10314884 0.1106634  0.10483231 0.09157773\n",
      "  0.0931111  0.09988175 0.09658814 0.09381499]\n",
      " [0.10978998 0.10467339 0.10664049 0.10923975 0.10639893 0.09107002\n",
      "  0.08789468 0.09660584 0.09213582 0.0955511 ]\n",
      " [0.10009523 0.09780938 0.10845679 0.10223836 0.10980925 0.09547909\n",
      "  0.09281838 0.10655539 0.09434683 0.09239127]\n",
      " [0.10433149 0.09158268 0.10384451 0.09740942 0.11218306 0.09210246\n",
      "  0.08859238 0.09438096 0.10880566 0.1067674 ]\n",
      " [0.10709531 0.09757575 0.0924383  0.09848618 0.10405735 0.10601049\n",
      "  0.08139934 0.10000493 0.11203252 0.10089985]\n",
      " [0.11051238 0.10178421 0.10142141 0.0988711  0.1060653  0.09471824\n",
      "  0.08994447 0.09735794 0.10056981 0.09875508]\n",
      " [0.11782321 0.10523214 0.11319308 0.09307196 0.11734209 0.09110169\n",
      "  0.08821251 0.09477085 0.08386816 0.09538431]\n",
      " [0.10624576 0.10412623 0.10791276 0.10440608 0.10660094 0.09801994\n",
      "  0.08901443 0.09725191 0.0975026  0.08891933]\n",
      " [0.10533066 0.09215309 0.09864746 0.10506322 0.11355717 0.09578069\n",
      "  0.09988377 0.09893908 0.09403794 0.09660687]\n",
      " [0.10459887 0.10000095 0.10803585 0.10428283 0.11785988 0.08757116\n",
      "  0.08646661 0.10299433 0.09412696 0.0940626 ]\n",
      " [0.10707089 0.11351459 0.10790542 0.09758843 0.10442896 0.0913409\n",
      "  0.08985976 0.096566   0.09998284 0.09174218]\n",
      " [0.11548544 0.09744573 0.11186852 0.10211764 0.10507907 0.09546225\n",
      "  0.09075756 0.1062948  0.08898815 0.08650087]\n",
      " [0.11045509 0.10063203 0.1026039  0.1019243  0.11215302 0.09616111\n",
      "  0.08520768 0.09958937 0.09267683 0.09859664]\n",
      " [0.11686025 0.10915914 0.10197961 0.09774014 0.11597205 0.10140502\n",
      "  0.08143835 0.09417768 0.09441069 0.08685716]\n",
      " [0.10148881 0.08645134 0.11200187 0.10031506 0.11329001 0.10131267\n",
      "  0.09150443 0.10224816 0.09399529 0.09739238]\n",
      " [0.10143563 0.08706298 0.10254759 0.10048359 0.10982554 0.10802414\n",
      "  0.08624129 0.0975816  0.11214856 0.0946491 ]\n",
      " [0.11865287 0.09880014 0.09001243 0.10507674 0.11074104 0.09817042\n",
      "  0.09419239 0.09442645 0.0916954  0.09823202]\n",
      " [0.11439319 0.09832738 0.10456103 0.10624246 0.10940746 0.0943261\n",
      "  0.09456661 0.10505997 0.08588488 0.08723096]\n",
      " [0.09994154 0.10552787 0.10811249 0.10437097 0.11265282 0.09059685\n",
      "  0.08289395 0.11148367 0.08645461 0.09796531]\n",
      " [0.12770303 0.09510607 0.1023353  0.09563212 0.11373398 0.09848043\n",
      "  0.09693275 0.08614855 0.08532768 0.09860004]\n",
      " [0.09673029 0.09835248 0.10997626 0.09133751 0.11423962 0.09433923\n",
      "  0.09264562 0.10190541 0.10338741 0.09708612]\n",
      " [0.10439152 0.10356395 0.09799874 0.10042046 0.10527427 0.10036476\n",
      "  0.09199623 0.09440187 0.1031174  0.09847073]\n",
      " [0.09943013 0.0962161  0.11750674 0.08579415 0.11081053 0.08942187\n",
      "  0.0930876  0.11279833 0.09594925 0.09898526]\n",
      " [0.10701305 0.10784613 0.10437986 0.10046445 0.10894497 0.10516084\n",
      "  0.08718767 0.09642462 0.08979842 0.09277999]\n",
      " [0.10166271 0.09570954 0.09394993 0.09951507 0.11046981 0.09148943\n",
      "  0.09506171 0.10670298 0.10629822 0.09914062]\n",
      " [0.11326043 0.09953599 0.09917049 0.10093293 0.10241635 0.09196692\n",
      "  0.09473294 0.09112929 0.10276894 0.10408581]\n",
      " [0.11343341 0.09824852 0.09368097 0.10265025 0.11395733 0.08497821\n",
      "  0.10234979 0.10711328 0.09099321 0.092595  ]\n",
      " [0.10432181 0.10547878 0.10588973 0.09890225 0.10092113 0.09534258\n",
      "  0.09071484 0.10302456 0.09495448 0.10044985]\n",
      " [0.10961013 0.09618679 0.10902484 0.10746731 0.11292949 0.09440702\n",
      "  0.09294847 0.09143448 0.0872583  0.09873311]\n",
      " [0.09756772 0.11268611 0.11112072 0.11422246 0.12368684 0.08357414\n",
      "  0.07830865 0.09668612 0.09442661 0.0877206 ]\n",
      " [0.10813316 0.09132614 0.10150102 0.09475385 0.10333579 0.1017867\n",
      "  0.10082296 0.10062256 0.10310296 0.09461486]\n",
      " [0.1188541  0.09454839 0.09373739 0.09759728 0.11922036 0.08750992\n",
      "  0.09361058 0.0927374  0.10221473 0.09996977]\n",
      " [0.10048967 0.10602807 0.10063672 0.10717276 0.09775431 0.08722737\n",
      "  0.10229415 0.09640266 0.10032424 0.10167004]\n",
      " [0.11990211 0.10503852 0.10555202 0.10117043 0.10018043 0.10240649\n",
      "  0.08464099 0.11092934 0.08745164 0.08272799]\n",
      " [0.0923655  0.10068224 0.11838784 0.10198013 0.11772734 0.0961331\n",
      "  0.08405918 0.09674377 0.10435891 0.08756202]\n",
      " [0.09435841 0.10390887 0.11813448 0.09517633 0.1203934  0.09692272\n",
      "  0.08134156 0.09866577 0.09498118 0.0961172 ]\n",
      " [0.11398689 0.10038338 0.09807884 0.10273191 0.11038402 0.09285407\n",
      "  0.09636243 0.09684131 0.09638944 0.09198771]\n",
      " [0.1080481  0.09172109 0.09967287 0.09834346 0.11476122 0.1022609\n",
      "  0.09386398 0.10268683 0.09738079 0.09126072]\n",
      " [0.10922854 0.10123904 0.10119864 0.10815532 0.1004898  0.08609604\n",
      "  0.09411687 0.09934926 0.11122574 0.08890079]\n",
      " [0.11255176 0.09461753 0.10512041 0.10835361 0.11003167 0.08849625\n",
      "  0.08733178 0.1030327  0.09457624 0.09588799]\n",
      " [0.11177597 0.1001163  0.10881425 0.09347513 0.10599359 0.09383196\n",
      "  0.09305119 0.09619027 0.10167433 0.09507697]\n",
      " [0.10411279 0.10777739 0.10152788 0.10104857 0.10352843 0.09413663\n",
      "  0.0931683  0.11325911 0.09578892 0.08565195]\n",
      " [0.11256135 0.11000022 0.10935535 0.1025824  0.1073958  0.08804659\n",
      "  0.08287448 0.1031536  0.09825716 0.08577299]\n",
      " [0.10580002 0.10766456 0.10313872 0.08482584 0.11042321 0.08531491\n",
      "  0.09141979 0.10586327 0.10302404 0.10252563]\n",
      " [0.10419858 0.10273479 0.10254778 0.09525716 0.11043866 0.09662068\n",
      "  0.09249932 0.09781932 0.0995694  0.09831435]\n",
      " [0.10491791 0.102446   0.09615922 0.09985609 0.11550932 0.0870461\n",
      "  0.08824942 0.09942262 0.10485112 0.10154223]\n",
      " [0.10485213 0.10533971 0.10097955 0.10563388 0.10674096 0.08619341\n",
      "  0.09048291 0.09849879 0.1064965  0.0947822 ]\n",
      " [0.11386508 0.09276954 0.10030033 0.10125466 0.11631463 0.09054922\n",
      "  0.09604009 0.09706955 0.0957145  0.09612238]\n",
      " [0.10006088 0.10086852 0.10482564 0.09963376 0.10327921 0.09367946\n",
      "  0.08408812 0.09957456 0.1128937  0.10109619]\n",
      " [0.11647971 0.1015136  0.09630597 0.10053515 0.1059326  0.09590091\n",
      "  0.09377816 0.10124738 0.09259412 0.09571242]\n",
      " [0.11651882 0.10439282 0.10405518 0.10162264 0.10459425 0.09167622\n",
      "  0.09256565 0.09001761 0.09806242 0.09649441]\n",
      " [0.11602399 0.08626035 0.09687833 0.10495661 0.12196285 0.08175066\n",
      "  0.09447669 0.1067581  0.10021183 0.09072055]\n",
      " [0.10305381 0.10321919 0.10766219 0.10505784 0.1125764  0.09115783\n",
      "  0.09155821 0.09728622 0.09380379 0.09462453]\n",
      " [0.10251343 0.1013512  0.10917407 0.10246006 0.11063364 0.08064687\n",
      "  0.08359082 0.09373511 0.11223736 0.10365742]\n",
      " [0.10664174 0.09813193 0.09524983 0.10028055 0.10957935 0.09616543\n",
      "  0.08930419 0.09315343 0.11432517 0.0971683 ]\n",
      " [0.10828612 0.09623292 0.10838212 0.09894476 0.11079507 0.09134447\n",
      "  0.09192401 0.10865512 0.09225737 0.09317807]\n",
      " [0.11461327 0.10001676 0.10401868 0.10170467 0.09952971 0.09275259\n",
      "  0.09044471 0.10722642 0.09700467 0.09268846]\n",
      " [0.10822685 0.10221729 0.09669284 0.10546368 0.10927331 0.10068113\n",
      "  0.08676063 0.10491467 0.09261005 0.09315952]\n",
      " [0.09916203 0.09515855 0.09871121 0.10009645 0.11380529 0.08727035\n",
      "  0.09387283 0.10611795 0.10431521 0.10149016]\n",
      " [0.10909848 0.10203607 0.10898715 0.10660999 0.11491617 0.08666956\n",
      "  0.09028932 0.10337285 0.09016722 0.08785325]\n",
      " [0.11414509 0.10737429 0.10538414 0.09209206 0.11311401 0.09912429\n",
      "  0.07946622 0.10170006 0.09947392 0.08812591]\n",
      " [0.10779773 0.10262179 0.10826018 0.10393298 0.10030714 0.09316663\n",
      "  0.08826315 0.09434276 0.09439255 0.10691512]\n",
      " [0.11075408 0.09825738 0.10181719 0.09355345 0.11233334 0.08936007\n",
      "  0.08778067 0.09671103 0.10469223 0.10474053]\n",
      " [0.09337543 0.1057608  0.10726642 0.08867142 0.10114203 0.12163334\n",
      "  0.08723688 0.09732126 0.09845866 0.09913385]\n",
      " [0.09615436 0.08911668 0.10252173 0.10841263 0.11210845 0.10790268\n",
      "  0.09775132 0.0933111  0.09952047 0.09320054]\n",
      " [0.10151477 0.10256124 0.09214026 0.09297528 0.10708311 0.08620643\n",
      "  0.09520201 0.10919844 0.09784691 0.11527152]\n",
      " [0.11242573 0.10866593 0.10421844 0.09138983 0.11750751 0.08324169\n",
      "  0.09151318 0.10480306 0.09927173 0.0869629 ]\n",
      " [0.10281078 0.10034481 0.11066018 0.09292992 0.10092913 0.09077477\n",
      "  0.08494455 0.11516431 0.10003091 0.10141067]\n",
      " [0.11631997 0.09935725 0.09774725 0.09939928 0.1156128  0.0847367\n",
      "  0.09287418 0.10043223 0.09991521 0.09360511]\n",
      " [0.10444851 0.10150623 0.09369738 0.10567472 0.11089961 0.09302731\n",
      "  0.08898054 0.10609031 0.09891761 0.09675775]\n",
      " [0.09589557 0.09603164 0.09478142 0.09889432 0.11194848 0.10112563\n",
      "  0.0940559  0.09784426 0.10476143 0.10466128]\n",
      " [0.10440517 0.10232715 0.09000781 0.10376671 0.12030023 0.08799506\n",
      "  0.08338317 0.09706865 0.1035981  0.10714795]\n",
      " [0.09851236 0.10449382 0.10483116 0.10244841 0.10462918 0.09397549\n",
      "  0.08098008 0.1092055  0.0917341  0.10918984]\n",
      " [0.10247106 0.10159378 0.10618553 0.10787088 0.10561618 0.08943098\n",
      "  0.07667716 0.10770142 0.11870138 0.08375164]\n",
      " [0.09960196 0.08830041 0.11114901 0.09908729 0.11155821 0.08946535\n",
      "  0.09416313 0.10537396 0.09822743 0.10307324]\n",
      " [0.09499281 0.09493376 0.10718112 0.09869234 0.11545618 0.08947311\n",
      "  0.09178295 0.10751088 0.09407885 0.10589804]\n",
      " [0.11278067 0.10064932 0.10522665 0.10899283 0.11082298 0.08769637\n",
      "  0.08691524 0.10016474 0.09517126 0.09157996]\n",
      " [0.10048155 0.09878615 0.10585117 0.09507189 0.10656935 0.07921782\n",
      "  0.09250744 0.1181509  0.10023335 0.1031304 ]\n",
      " [0.11185545 0.10212234 0.10118674 0.10726278 0.10196212 0.09854338\n",
      "  0.09738338 0.09759973 0.09545796 0.08662606]\n",
      " [0.11255264 0.09602288 0.10715958 0.10666297 0.10846262 0.09577011\n",
      "  0.09275915 0.09028585 0.09587456 0.09444971]\n",
      " [0.09338024 0.10603459 0.11047648 0.10392879 0.11021844 0.09475926\n",
      "  0.08703864 0.10081813 0.09698833 0.09635711]\n",
      " [0.109549   0.09287867 0.09979489 0.10332552 0.11186995 0.09276985\n",
      "  0.08891536 0.11202212 0.09134045 0.09753415]\n",
      " [0.11218727 0.10355533 0.10431217 0.10125571 0.09853794 0.0952913\n",
      "  0.09491549 0.09740097 0.09649013 0.09605367]\n",
      " [0.1132755  0.09689473 0.10082956 0.10339843 0.10540003 0.09384608\n",
      "  0.09751239 0.10308901 0.09227151 0.09348275]\n",
      " [0.09526877 0.10835281 0.10930569 0.1030608  0.11771777 0.09722431\n",
      "  0.09519786 0.09238802 0.09871481 0.0827691 ]\n",
      " [0.09997631 0.09902839 0.10290086 0.08949452 0.10994286 0.09417906\n",
      "  0.09970059 0.10971436 0.09595453 0.09910853]\n",
      " [0.11861054 0.10138889 0.10040373 0.10478523 0.10784211 0.09328176\n",
      "  0.08721389 0.09624131 0.09455456 0.09567804]\n",
      " [0.09728573 0.09993847 0.11343164 0.09497239 0.11279177 0.09621966\n",
      "  0.08317808 0.10207127 0.09599088 0.10412015]\n",
      " [0.08962318 0.1096966  0.10483427 0.09625678 0.10371108 0.08996835\n",
      "  0.09236473 0.11197639 0.103456   0.09811267]\n",
      " [0.11242136 0.09908251 0.10024931 0.10696367 0.09995948 0.10409888\n",
      "  0.08880933 0.10623223 0.08186805 0.10031516]\n",
      " [0.1292411  0.10351141 0.1058645  0.09219768 0.10494067 0.0808467\n",
      "  0.09200718 0.11388502 0.08689873 0.090607  ]\n",
      " [0.10835572 0.09277324 0.09906478 0.10492731 0.11846334 0.09413951\n",
      "  0.09485416 0.10215335 0.09669973 0.08856884]\n",
      " [0.10352489 0.10876104 0.1118438  0.11046986 0.11285633 0.08795463\n",
      "  0.08349918 0.0884146  0.10388676 0.08878892]\n",
      " [0.11269153 0.09634743 0.10215881 0.0932669  0.10806991 0.09436135\n",
      "  0.08812418 0.09531798 0.11454362 0.09511831]\n",
      " [0.10486342 0.10460991 0.10168175 0.10431486 0.10096241 0.09451381\n",
      "  0.08689683 0.10293439 0.10145787 0.09776475]\n",
      " [0.1096125  0.09441786 0.10661545 0.09839612 0.10236667 0.09208892\n",
      "  0.09397241 0.10280553 0.10140003 0.09832446]\n",
      " [0.10815836 0.09033917 0.09675963 0.11244956 0.10661294 0.09636176\n",
      "  0.09309788 0.09245298 0.0999124  0.10385528]\n",
      " [0.09299049 0.09505166 0.11055429 0.10051411 0.10825473 0.10585926\n",
      "  0.08060652 0.10605723 0.09949891 0.10061286]\n",
      " [0.11215794 0.10348295 0.09625573 0.10093153 0.12104384 0.08640713\n",
      "  0.08803317 0.10113899 0.09951629 0.09103248]]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:step = 1, loss = 2.31313\n",
      "INFO:tensorflow:probabilities = [[0.10345973 0.1053324  0.11260445 0.1095344  0.10865138 0.09529361\n",
      "  0.08057024 0.09730025 0.09265815 0.09459549]\n",
      " [0.10828603 0.09589201 0.0882613  0.08992352 0.1179796  0.09525742\n",
      "  0.09712285 0.10003143 0.11284091 0.09440497]\n",
      " [0.10761333 0.09632732 0.10276283 0.10631852 0.10649116 0.10167152\n",
      "  0.09031847 0.09849342 0.0999727  0.09003071]\n",
      " [0.11209444 0.0999964  0.10101243 0.10395797 0.10049949 0.09585789\n",
      "  0.09164061 0.09960716 0.10306362 0.09226996]\n",
      " [0.10571341 0.08878682 0.1008701  0.10672241 0.11891192 0.10657118\n",
      "  0.0978503  0.0884326  0.09148329 0.09465799]\n",
      " [0.10437703 0.09981944 0.10191327 0.10238753 0.10775653 0.08982103\n",
      "  0.09123843 0.10136294 0.10011918 0.10120462]\n",
      " [0.10955931 0.10269233 0.10461085 0.09527165 0.10688049 0.08747648\n",
      "  0.08857793 0.10567805 0.10269978 0.09655308]\n",
      " [0.11331647 0.09528522 0.10123994 0.12431024 0.11705815 0.07693159\n",
      "  0.09505143 0.10385184 0.09661759 0.07633746]\n",
      " [0.10512358 0.09958644 0.10887939 0.09835219 0.10461567 0.09041453\n",
      "  0.09853461 0.10520998 0.09483997 0.09444362]\n",
      " [0.11113077 0.09031221 0.09102155 0.09800829 0.11803995 0.09734083\n",
      "  0.0955598  0.09918173 0.10729586 0.09210905]\n",
      " [0.09505317 0.10279616 0.1161062  0.10145584 0.10143135 0.08417752\n",
      "  0.10126969 0.09630142 0.09886584 0.10254275]\n",
      " [0.11371616 0.09199011 0.09516912 0.11128254 0.10215089 0.08714847\n",
      "  0.10655268 0.10042048 0.09970774 0.09186181]\n",
      " [0.11304278 0.09568648 0.10123983 0.11349244 0.10483357 0.09307537\n",
      "  0.08836664 0.09358922 0.09390209 0.10277156]\n",
      " [0.11335067 0.10228291 0.09732574 0.09411179 0.11569332 0.10281081\n",
      "  0.09713956 0.09584659 0.09500251 0.08643607]\n",
      " [0.10151952 0.09794061 0.11365385 0.10805072 0.10722602 0.09365188\n",
      "  0.09665167 0.09764981 0.09850122 0.08515463]\n",
      " [0.105462   0.10168088 0.1008554  0.09883208 0.09907672 0.10073096\n",
      "  0.09100514 0.10501986 0.1001507  0.0971863 ]\n",
      " [0.1135812  0.1011163  0.10439745 0.09345074 0.10789353 0.09157785\n",
      "  0.09244023 0.10087276 0.10307385 0.09159618]\n",
      " [0.10332167 0.1002794  0.10613153 0.10411178 0.10580067 0.09493442\n",
      "  0.08910906 0.09470835 0.09737211 0.10423099]\n",
      " [0.10764254 0.10034771 0.10104243 0.09950114 0.11161906 0.09004434\n",
      "  0.09326195 0.08841068 0.11338552 0.09474463]\n",
      " [0.1058889  0.09365854 0.09570226 0.10455547 0.11992404 0.08318149\n",
      "  0.09976773 0.09688051 0.1041038  0.09633721]\n",
      " [0.10837479 0.1019203  0.10998818 0.10249973 0.11389406 0.08447644\n",
      "  0.09607352 0.10680109 0.09583371 0.08013818]\n",
      " [0.11182687 0.09742758 0.11308096 0.10570833 0.09408456 0.09270153\n",
      "  0.09050982 0.09775551 0.10075851 0.09614636]\n",
      " [0.1102707  0.09640155 0.10284566 0.10163056 0.1043376  0.09079905\n",
      "  0.09832048 0.10028729 0.09563222 0.09947485]\n",
      " [0.10154328 0.11103944 0.09866647 0.10478672 0.10067789 0.0912213\n",
      "  0.08821668 0.09843416 0.10611567 0.09929838]\n",
      " [0.10176308 0.09886597 0.10042273 0.10515365 0.1112096  0.0916887\n",
      "  0.10099871 0.10759518 0.0907518  0.09155048]\n",
      " [0.10594674 0.09478913 0.11049863 0.10539535 0.11165767 0.09455241\n",
      "  0.09373055 0.09746823 0.09849495 0.08746627]\n",
      " [0.09655393 0.08265402 0.10594582 0.11866705 0.1144748  0.08755229\n",
      "  0.08954909 0.09711238 0.10375581 0.10373477]\n",
      " [0.10172478 0.10338242 0.10963843 0.09501791 0.09968731 0.10319605\n",
      "  0.09353935 0.09910021 0.10299011 0.0917235 ]\n",
      " [0.10995849 0.09557845 0.10724474 0.09605828 0.11485931 0.09525991\n",
      "  0.08782554 0.09654591 0.09430548 0.10236389]\n",
      " [0.0993785  0.10121812 0.10230743 0.10098284 0.11668794 0.08917239\n",
      "  0.1012039  0.09605604 0.09925023 0.09374265]\n",
      " [0.09231842 0.10801277 0.10948347 0.09665719 0.10892994 0.10109288\n",
      "  0.09604414 0.09908886 0.10140918 0.08696319]\n",
      " [0.11487521 0.10973662 0.10749385 0.0982495  0.09894007 0.09592773\n",
      "  0.07791282 0.11239267 0.0908407  0.09363084]\n",
      " [0.1138199  0.09941112 0.10206082 0.10094532 0.10610546 0.08340602\n",
      "  0.09879129 0.10620544 0.08941383 0.09984083]\n",
      " [0.1092277  0.10521159 0.09785858 0.10997101 0.10209758 0.09464846\n",
      "  0.09182533 0.10581857 0.0923862  0.09095494]\n",
      " [0.10051746 0.10980441 0.10493634 0.10068446 0.11498485 0.08493461\n",
      "  0.0872392  0.09456119 0.09798255 0.10435488]\n",
      " [0.10970387 0.09416787 0.1065245  0.09364157 0.11021265 0.08993281\n",
      "  0.09666608 0.10470623 0.09631284 0.09813157]\n",
      " [0.10565697 0.10321653 0.09763288 0.10054342 0.0998321  0.09422975\n",
      "  0.10256279 0.1015675  0.08999248 0.10476557]\n",
      " [0.10649809 0.10671651 0.10634965 0.09572113 0.10663669 0.09344109\n",
      "  0.09277669 0.10220785 0.09917457 0.09047776]\n",
      " [0.11234064 0.10272144 0.10559789 0.09981122 0.1085923  0.0948302\n",
      "  0.09615799 0.09560038 0.09457336 0.08977452]\n",
      " [0.10590444 0.09261017 0.09889776 0.10479276 0.11781435 0.09543931\n",
      "  0.09379712 0.09862041 0.09399202 0.09813163]\n",
      " [0.10317869 0.11175116 0.10389173 0.10842916 0.10062265 0.08396668\n",
      "  0.10519743 0.09534829 0.09887076 0.08874343]\n",
      " [0.09714623 0.0991778  0.09732954 0.09987106 0.11237059 0.08904206\n",
      "  0.09024593 0.09993011 0.1023035  0.11258318]\n",
      " [0.10623434 0.09786298 0.10685845 0.10277586 0.10345849 0.09137803\n",
      "  0.09376456 0.10547872 0.10405106 0.08813749]\n",
      " [0.10066023 0.09901442 0.10363382 0.10299398 0.10923252 0.10610563\n",
      "  0.09230376 0.09475842 0.09572857 0.09556871]\n",
      " [0.09567896 0.11050724 0.10092164 0.09645393 0.11069236 0.08954044\n",
      "  0.0937248  0.10300212 0.10172328 0.09775528]\n",
      " [0.11974842 0.10611754 0.09628612 0.10067797 0.09839761 0.09429485\n",
      "  0.08946918 0.1059198  0.09693503 0.0921535 ]\n",
      " [0.10185992 0.10021147 0.09339204 0.10776416 0.10840719 0.08917248\n",
      "  0.09905311 0.11063053 0.09547079 0.09403827]\n",
      " [0.11301267 0.09584132 0.08836538 0.10151669 0.10301407 0.09306154\n",
      "  0.10543022 0.09971239 0.0989354  0.10111035]\n",
      " [0.11930791 0.095755   0.09509045 0.10098383 0.10866078 0.10231027\n",
      "  0.09081046 0.09787506 0.09640535 0.09280091]\n",
      " [0.10648069 0.09924456 0.09247636 0.10325907 0.11427937 0.09213795\n",
      "  0.08758508 0.11040993 0.10004822 0.09407876]\n",
      " [0.10237692 0.08008934 0.09824306 0.1070019  0.12192188 0.10079728\n",
      "  0.09791098 0.09101343 0.10079063 0.09985455]\n",
      " [0.10597616 0.08845416 0.11643425 0.10995645 0.10920495 0.09764843\n",
      "  0.08553208 0.08279946 0.10313656 0.10085747]\n",
      " [0.09991784 0.10224856 0.10574454 0.10444365 0.09713608 0.09823956\n",
      "  0.08984968 0.10152485 0.10577016 0.09512503]\n",
      " [0.10457509 0.09598599 0.10863816 0.09495881 0.11424743 0.09640712\n",
      "  0.08404101 0.10352594 0.09780143 0.09981902]\n",
      " [0.11360957 0.10791009 0.10298467 0.10155942 0.09806617 0.09475427\n",
      "  0.09194231 0.10105935 0.09812737 0.0899868 ]\n",
      " [0.1176216  0.10665249 0.09817494 0.09632058 0.10938369 0.09102635\n",
      "  0.09013095 0.10275392 0.09335101 0.09458452]\n",
      " [0.11039034 0.10351514 0.08989815 0.10455523 0.11366332 0.08957928\n",
      "  0.08684991 0.09619219 0.10952602 0.09583046]\n",
      " [0.09926348 0.10113459 0.11157707 0.10236517 0.10294264 0.09477074\n",
      "  0.07933901 0.10123818 0.1052371  0.10213204]\n",
      " [0.10730987 0.10772783 0.09866911 0.10704684 0.09598511 0.09275304\n",
      "  0.08733609 0.10107662 0.10607187 0.09602363]\n",
      " [0.11170373 0.10880863 0.10381365 0.1031938  0.09711388 0.09362897\n",
      "  0.0904429  0.10176218 0.09373496 0.09579732]\n",
      " [0.10263851 0.1012463  0.10625744 0.09505687 0.10214595 0.09567927\n",
      "  0.09105202 0.10799401 0.10378981 0.09413988]\n",
      " [0.10388377 0.09426972 0.11670938 0.1040737  0.11034271 0.08906265\n",
      "  0.09725327 0.103908   0.08775739 0.09273944]\n",
      " [0.11409448 0.09836695 0.1000463  0.10636549 0.10231539 0.09047414\n",
      "  0.09419483 0.10051802 0.09571706 0.09790734]\n",
      " [0.1053523  0.09724836 0.10801727 0.11007101 0.11718231 0.09151457\n",
      "  0.08240283 0.09860075 0.09798953 0.0916211 ]\n",
      " [0.11365671 0.09538442 0.09733907 0.10146503 0.11771367 0.08276313\n",
      "  0.08567882 0.1045934  0.10188738 0.09951838]\n",
      " [0.09977791 0.10803638 0.10625576 0.10201234 0.1015796  0.10667925\n",
      "  0.08669177 0.10117663 0.09353601 0.09425432]\n",
      " [0.10415823 0.09232596 0.09861679 0.10510575 0.10674559 0.10063301\n",
      "  0.09636493 0.09981135 0.09717342 0.09906495]\n",
      " [0.11225627 0.10811651 0.10104408 0.10837937 0.09760763 0.0930204\n",
      "  0.08585531 0.10168779 0.09292965 0.09910295]\n",
      " [0.09480499 0.09972241 0.10379841 0.1059016  0.11027636 0.0918052\n",
      "  0.09711514 0.10827444 0.09546528 0.09283623]\n",
      " [0.09964735 0.10150012 0.10396659 0.08579783 0.10232839 0.10564239\n",
      "  0.10393894 0.10662076 0.08904643 0.10151119]\n",
      " [0.10535435 0.09445962 0.09917496 0.10703918 0.11396512 0.09328452\n",
      "  0.09624276 0.0927031  0.09988323 0.09789312]\n",
      " [0.11315852 0.1007825  0.10065057 0.09875094 0.09793704 0.09075478\n",
      "  0.09759185 0.09809481 0.09749814 0.10478091]\n",
      " [0.11624406 0.10054693 0.09766222 0.09648516 0.09809118 0.09701231\n",
      "  0.09330135 0.0994264  0.10203145 0.09919892]\n",
      " [0.11295062 0.09112271 0.10367628 0.10816892 0.11813845 0.08018133\n",
      "  0.0951378  0.10571351 0.09662957 0.08828083]\n",
      " [0.11601315 0.1013613  0.11219037 0.11204644 0.11128931 0.08301557\n",
      "  0.09120972 0.09247342 0.09395874 0.08644195]\n",
      " [0.09985414 0.10101262 0.10314494 0.09473451 0.10447291 0.0944526\n",
      "  0.09445748 0.09836341 0.10126055 0.1082468 ]\n",
      " [0.10107563 0.10132859 0.11116938 0.09857957 0.10652786 0.09329793\n",
      "  0.09837899 0.10249198 0.09232624 0.09482383]\n",
      " [0.10694946 0.09470138 0.11013515 0.1093838  0.10922938 0.09451265\n",
      "  0.09753717 0.09215496 0.10446817 0.08092788]\n",
      " [0.12196511 0.09089764 0.10079637 0.10055315 0.11741415 0.10267485\n",
      "  0.08511831 0.09950007 0.09541173 0.0856686 ]\n",
      " [0.10797906 0.10019597 0.09907161 0.10423245 0.10503343 0.09533966\n",
      "  0.10110588 0.09951637 0.09526523 0.0922603 ]\n",
      " [0.09863129 0.09797438 0.09201283 0.10625933 0.11215673 0.09120452\n",
      "  0.0890591  0.1114165  0.09794249 0.10334282]\n",
      " [0.10770912 0.10930484 0.11022118 0.0943236  0.10366198 0.08822731\n",
      "  0.08761729 0.10198765 0.09782474 0.09912234]\n",
      " [0.106829   0.10690849 0.10288689 0.09698695 0.10368259 0.10003672\n",
      "  0.0876571  0.10530563 0.0938665  0.09584007]\n",
      " [0.10287014 0.10165604 0.10465759 0.10305929 0.114696   0.09199129\n",
      "  0.09244318 0.10126197 0.08856097 0.09880351]\n",
      " [0.10457128 0.11336366 0.1062751  0.1007374  0.11230659 0.09155894\n",
      "  0.08635286 0.09421262 0.09864275 0.09197879]\n",
      " [0.10853814 0.09218439 0.10536604 0.11215496 0.11003515 0.08745299\n",
      "  0.08364153 0.10178947 0.09465727 0.10418008]\n",
      " [0.10925726 0.10175466 0.10341007 0.10452836 0.10869835 0.07991669\n",
      "  0.09233027 0.10464083 0.09532506 0.10013842]\n",
      " [0.11820151 0.10395515 0.10677848 0.10018604 0.10696483 0.09559458\n",
      "  0.0871387  0.09786592 0.09117808 0.0921367 ]\n",
      " [0.10169289 0.11398854 0.09798994 0.10018831 0.1015617  0.09339707\n",
      "  0.09278695 0.10540508 0.1007376  0.09225197]\n",
      " [0.10883155 0.10220163 0.10603224 0.1108413  0.11237012 0.09975837\n",
      "  0.09245832 0.09877533 0.08702341 0.08170777]\n",
      " [0.10572189 0.09564201 0.09085172 0.10249524 0.10580403 0.11065397\n",
      "  0.09085193 0.09951261 0.10160907 0.09685756]\n",
      " [0.09848009 0.1042786  0.10566559 0.098219   0.10758148 0.09934746\n",
      "  0.08989572 0.09547128 0.1112155  0.08984528]\n",
      " [0.11079452 0.09335944 0.09917876 0.0998106  0.10707283 0.09028478\n",
      "  0.09791484 0.09885191 0.10075939 0.10197296]\n",
      " [0.10945924 0.09849348 0.10396625 0.09342509 0.11168215 0.0950416\n",
      "  0.09048416 0.10262948 0.10210355 0.09271504]\n",
      " [0.11201303 0.09637284 0.098683   0.10527628 0.10878351 0.09733292\n",
      "  0.09722624 0.10092974 0.09029197 0.09309049]\n",
      " [0.10486799 0.10093415 0.10193541 0.10563125 0.09952132 0.10676169\n",
      "  0.08861893 0.10205164 0.09553999 0.09413761]\n",
      " [0.11210458 0.10086823 0.09424103 0.10636289 0.10515258 0.09046353\n",
      "  0.08683534 0.09854856 0.10965476 0.09576854]\n",
      " [0.09385379 0.10293241 0.11406156 0.09737955 0.1015162  0.09752336\n",
      "  0.09449681 0.10511797 0.10469577 0.08842259]\n",
      " [0.10811957 0.09616623 0.10049542 0.10675358 0.11362923 0.08673241\n",
      "  0.10040378 0.10688104 0.09043181 0.09038696]\n",
      " [0.10718651 0.09537045 0.10601004 0.11047162 0.10929431 0.08722991\n",
      "  0.1055134  0.09779582 0.08773027 0.09339771]] (0.263 sec)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Saving checkpoints for 100 into /tmp/mnist_convnet_model/model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 2.2849605.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2018-07-23-08:52:42\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from /tmp/mnist_convnet_model/model.ckpt-100\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2018-07-23-08:52:43\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.1363, global_step = 100, loss = 2.2880392\n",
      "{'accuracy': 0.1363, 'loss': 2.2880392, 'global_step': 100}\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[0;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/media/xd/000398040009E3B2/txh_ubuntu/anaconda3/envs/tensorflow/lib/python3.5/site-packages/IPython/core/interactiveshell.py:2971: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "def main(unused_argv):\n",
    "  # Load training and eval data\n",
    "  mnist = tf.contrib.learn.datasets.load_dataset(\"mnist\")\n",
    "  train_data = mnist.train.images  # Returns np.array\n",
    "  train_labels = np.asarray(mnist.train.labels, dtype=np.int32)\n",
    "  eval_data = mnist.test.images  # Returns np.array\n",
    "  eval_labels = np.asarray(mnist.test.labels, dtype=np.int32)\n",
    "\n",
    "  # Create the Estimator\n",
    "  mnist_classifier = tf.estimator.Estimator(\n",
    "      model_fn=cnn_model_fn, model_dir=\"/tmp/mnist_convnet_model\")\n",
    "\n",
    "  # Set up logging for predictions\n",
    "  # Log the values in the \"Softmax\" tensor with label \"probabilities\"\n",
    "  tensors_to_log = {\"probabilities\": \"softmax_tensor\"}\n",
    "  logging_hook = tf.train.LoggingTensorHook(\n",
    "      tensors=tensors_to_log, every_n_iter=50)\n",
    "\n",
    "  # Train the model\n",
    "  train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": train_data},\n",
    "      y=train_labels,\n",
    "      batch_size=100,\n",
    "      num_epochs=None,\n",
    "      shuffle=True)\n",
    "  mnist_classifier.train(\n",
    "      input_fn=train_input_fn,\n",
    "      steps=100,\n",
    "      hooks=[logging_hook])\n",
    "\n",
    "  # Evaluate the model and print results\n",
    "  eval_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "      x={\"x\": eval_data},\n",
    "      y=eval_labels,\n",
    "      num_epochs=1,\n",
    "      shuffle=False)\n",
    "  eval_results = mnist_classifier.evaluate(input_fn=eval_input_fn)\n",
    "  print(eval_results)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "  tf.app.run()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
